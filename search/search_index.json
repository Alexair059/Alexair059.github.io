{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome To My Blog \u00b6 For the days leaving","title":"Home"},{"location":"#welcome-to-my-blog","text":"For the days leaving","title":"Welcome To My Blog"},{"location":"ai/todo/","text":"Todo \u00b6","title":"ML"},{"location":"ai/todo/#todo","text":"","title":"Todo"},{"location":"ai/todo1/","text":"Todo \u00b6","title":"CV"},{"location":"ai/todo1/#todo","text":"","title":"Todo"},{"location":"ai/todo2/","text":"Todo \u00b6","title":"NLP"},{"location":"ai/todo2/#todo","text":"","title":"Todo"},{"location":"ai/todo3/","text":"Todo \u00b6","title":"KG"},{"location":"ai/todo3/#todo","text":"","title":"Todo"},{"location":"ai/todo4/","text":"Todo \u00b6","title":"DL"},{"location":"ai/todo4/#todo","text":"","title":"Todo"},{"location":"ai/todo5/","text":"Todo \u00b6","title":"RL"},{"location":"ai/todo5/#todo","text":"","title":"Todo"},{"location":"ctf/ch1/","text":"\u4e71\u6570\u5047\u6587\uff08Lorem ipsum\uff09 \u00b6 \u5bf9 lvl8 \u6587\u4ef6\u8fdb\u884cfile\u5206\u6790\uff0c\u53d1\u73b0\u662f\u4e00\u4e2a\u6587\u672c\u5185\u5bb9\u6587\u4ef6\uff1a \u53d1\u73b0\u5f62\u5f0f\u4e0a\u5f88\u50cf\u4e71\u6570\u5047\u6587 \u200b Lorem ipsum\uff0c\u4e2d\u6587\u53c8\u79f0\u201c\u4e71\u6570\u5047\u6587\u201d\uff0c \u662f\u6307\u4e00\u7bc7\u5e38\u7528\u4e8e\u6392\u7248\u8bbe\u8ba1\u9886\u57df\u7684\u62c9\u4e01\u6587\u6587\u7ae0\u3002\u76ee\u7684\u662f\u8ba9\u9605\u8bfb\u8005\u4e0d\u8981\u88ab\u6587\u7ae0\u5185\u5bb9\u6240\u5f71\u54cd\uff0c\u800c\u53ea\u4e13\u6ce8\u4e8e\u89c2\u5bdf\u5b57\u578b\u6216\u7248\u578b\uff0c\u5e76\u501f\u6b64\u586b\u6ee1\u7a7a\u95f4\u3002 \u4f46\u662f\u660e\u663e\u4e0d\u7b26\u5408\u6b63\u5e38\u7684\u5927\u5c0f\u5199\u547d\u540d \u6211\u4eec\u5408\u7406\u731c\u6d4b\u5e94\u8be5\u662f\u5c06\u76ee\u6807\u5185\u5bb9\u52a0\u5bc6\u5728\u4e86\u6587\u672c\u5f53\u4e2d \u6211\u4eec\u5047\u8bbe\u4e8c\u8fdb\u5236\u6587\u4ef6\u662f\u4f7f\u7528\u5b57\u7b26\u5927\u5c0f\u5199\u7f16\u7801\u7684\uff0c\u4e3a\u6b64\u6211\u4eec\u5ffd\u7565\u6240\u6709\u5176\u4ed6\u5b57\u7b26\uff0c\u5982\u6807\u70b9\u7b26\u53f7\u3001\u7a7a\u683c\u3001\u6362\u884c\u7b26\u7b49\uff0c\u5c06\u5927\u5199\u5b57\u6bcd\u8f6c\u6362\u4e3a1\uff0c\u5c0f\u5199\u5b57\u6bcd\u8f6c\u6362\u4e3a0 \u5728\u7f16\u5199python\u811a\u672c\u8fdb\u884c\u8f6c\u6362\u540e\uff0c\u6211\u4eec\u53d1\u73b0\u6587\u4ef6\u5f00\u5934ASCII\u7801\u4e3a\uff1a \u5b83\u867d\u7136\u4e0d\u662fELF\u6267\u884c\u6587\u4ef6\uff0c\u4f46\u662f\u6211\u4eec\u4e5f\u80fd\u5f97\u77e5\u8fd9\u662f\u4e00\u5f20\u4f4d\u56fe\u5f00\u5934\u6807\u8bc6\u7b26\uff0c\u6211\u4eec\u5c06\u5176\u4ee5\u56fe\u5f62\u5f0f\u6253\u5f00 \u4f4d\u56fe\u6587\u4ef6 \u00b6 \u8f6c\u6362\u540e\uff0c\u6211\u4eec\u5f97\u5230\u8be5\u56fe\uff1a \u5728\u591a\u65b9\u9762\u5c1d\u8bd5\u540e\uff08\u4f8b\u5982\u56fe\u7247\u5bbd\u9ad8\u3001\u6587\u4ef6\u683c\u5f0f\u3001\u5185\u5bb9\u7f16\u7801\u7b49\uff09\uff0c\u4ecd\u6ca1\u6709\u660e\u663e\u53ef\u7591\u5730\u65b9\u540e\uff0c\u6211\u4eec\u5c1d\u8bd5\u5229\u7528\u8f83\u4e3a\u5168\u9762\u7684\u56fe\u7247\u5206\u6790\u5de5\u5177ImageMagick\u8fdb\u884c\u68c0\u6d4b\uff1a \u5229\u7528 identify -verbose level8.bmp \u547d\u4ee4\u6211\u4eec\u53d1\u73b0\u4e00\u4e2a\u53ef\u7591\u7684\u5730\u65b9 \u8868\u793a\u989c\u8272\u79cd\u7c7b\u6570\u591a\u8fbe42\u79cd\uff0c\u4f46\u4ece\u56fe\u4e2d\u5f88\u660e\u663e\u5e76\u6ca1\u6709\u8fd9\u4e48\u591a\uff0c\u901a\u8fc7\u8c03\u8282\u5bf9\u6bd4\u5ea6\u4e0e\u4eae\u5ea6\u540e \u53ef\u4ee5\u770b\u5230\u56fe\u7247\u4e0b\u65b9\u91c7\u53d6\u4e86\u7591\u4f3cLSB\u9690\u5199\u7684\u6280\u672f \u9690\u5199\u672f \u00b6 \u5728\u56fe\u50cf\u6587\u4ef6\u4e2d\u9690\u85cf\u6570\u636e\u7684\u4e00\u79cd\u5e38\u89c1\u800c\u7b80\u5355\u7684\u9690\u5199\u6280\u672f \u901a\u8fc7\u7a0d\u5fae\u4fee\u6539\u56fe\u50cf\u50cf\u7d20\u7684RGB\u503c\uff0c\u6211\u4eec\u53ef\u4ee5\u5d4c\u5165\u8981\u9690\u85cf\u7684\u6570\u636e\uff1a\u5c06\u60f3\u8981\u9690\u85cf\u7684\u6570\u636e\u4f4d\u8986\u76d6\u7ea2\u8272\u3001\u7eff\u8272\u548c\u84dd\u8272\u901a\u9053\u7684\u6700\u4f4e\u6709\u6548\u4f4d\uff0c\u79f0\u4e3aLSB\u9690\u5199 \u4f8b\u5982\u5728\u8be5\u56fe\u4e2d\u6211\u4eec\u4ec5\u6539\u53d8\u4e86G\u901a\u9053\u4e0a\u7684LSB\uff0c\u5bf9\u989c\u8272\u7684\u6539\u53d8\u4e5f\u4ec5\u4ec5\u7531 #6490F1 \u53d8\u4e3a\u4e86 #6491F1\uff0c\u4ece\u8089\u773c\u4e0a\u662f\u96be\u4ee5\u533a\u5206\u7684\uff0c\u4f46\u7406\u8bba\u4e0a\u4e00\u5f20 W \\(\\times\\) H \u7684\u4f4d\u56fe\u80fd\u63d0\u4f9b\u6700\u5927 W \\(\\times\\) H \\(\\times\\) 3\\8 \u5b57\u8282\u7684\u9690\u5199\u7a7a\u95f4 \u5229\u7528\u5e38\u89c1\u7684LSB\u9690\u5199\u5de5\u5177\uff0c\u6211\u4eec\u53ef\u4ee5\u68c0\u6d4bbmp\u662f\u5426\u7ecf\u8fc7\u5e38\u89c1\u7684LSB\u52a0\u5bc6\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528zsteg\uff1a \u53ef\u4ee5\u770b\u5230\u5728b1\u4f4d\u4e0a\u7ecf\u8fc7LSB\u89e3\u5bc6\u68c0\u6d4b\u5230ELF\u7684\u6587\u4ef6\u6807\u8bc6\u7b26\uff0c\u8bf4\u660e\u8fd9\u6781\u6709\u53ef\u80fd\u662f\u88ab\u52a0\u5bc6\u9690\u85cf\u7684\u6587\u4ef6 \u6211\u4eec\u5229\u7528zsteg\u8fdb\u884c\u63d0\u53d6\uff1a \u901a\u8fc7file\u5de5\u5177\u53ef\u4ee5\u786e\u8ba4\u8fd9\u662f\u9700\u8981\u5f97\u5230\u7684\u9690\u5199ELF\u6587\u4ef6","title":"\u4e71\u6570\u5047\u6587&LSB\u9690\u5199"},{"location":"ctf/ch1/#lorem-ipsum","text":"\u5bf9 lvl8 \u6587\u4ef6\u8fdb\u884cfile\u5206\u6790\uff0c\u53d1\u73b0\u662f\u4e00\u4e2a\u6587\u672c\u5185\u5bb9\u6587\u4ef6\uff1a \u53d1\u73b0\u5f62\u5f0f\u4e0a\u5f88\u50cf\u4e71\u6570\u5047\u6587 \u200b Lorem ipsum\uff0c\u4e2d\u6587\u53c8\u79f0\u201c\u4e71\u6570\u5047\u6587\u201d\uff0c \u662f\u6307\u4e00\u7bc7\u5e38\u7528\u4e8e\u6392\u7248\u8bbe\u8ba1\u9886\u57df\u7684\u62c9\u4e01\u6587\u6587\u7ae0\u3002\u76ee\u7684\u662f\u8ba9\u9605\u8bfb\u8005\u4e0d\u8981\u88ab\u6587\u7ae0\u5185\u5bb9\u6240\u5f71\u54cd\uff0c\u800c\u53ea\u4e13\u6ce8\u4e8e\u89c2\u5bdf\u5b57\u578b\u6216\u7248\u578b\uff0c\u5e76\u501f\u6b64\u586b\u6ee1\u7a7a\u95f4\u3002 \u4f46\u662f\u660e\u663e\u4e0d\u7b26\u5408\u6b63\u5e38\u7684\u5927\u5c0f\u5199\u547d\u540d \u6211\u4eec\u5408\u7406\u731c\u6d4b\u5e94\u8be5\u662f\u5c06\u76ee\u6807\u5185\u5bb9\u52a0\u5bc6\u5728\u4e86\u6587\u672c\u5f53\u4e2d \u6211\u4eec\u5047\u8bbe\u4e8c\u8fdb\u5236\u6587\u4ef6\u662f\u4f7f\u7528\u5b57\u7b26\u5927\u5c0f\u5199\u7f16\u7801\u7684\uff0c\u4e3a\u6b64\u6211\u4eec\u5ffd\u7565\u6240\u6709\u5176\u4ed6\u5b57\u7b26\uff0c\u5982\u6807\u70b9\u7b26\u53f7\u3001\u7a7a\u683c\u3001\u6362\u884c\u7b26\u7b49\uff0c\u5c06\u5927\u5199\u5b57\u6bcd\u8f6c\u6362\u4e3a1\uff0c\u5c0f\u5199\u5b57\u6bcd\u8f6c\u6362\u4e3a0 \u5728\u7f16\u5199python\u811a\u672c\u8fdb\u884c\u8f6c\u6362\u540e\uff0c\u6211\u4eec\u53d1\u73b0\u6587\u4ef6\u5f00\u5934ASCII\u7801\u4e3a\uff1a \u5b83\u867d\u7136\u4e0d\u662fELF\u6267\u884c\u6587\u4ef6\uff0c\u4f46\u662f\u6211\u4eec\u4e5f\u80fd\u5f97\u77e5\u8fd9\u662f\u4e00\u5f20\u4f4d\u56fe\u5f00\u5934\u6807\u8bc6\u7b26\uff0c\u6211\u4eec\u5c06\u5176\u4ee5\u56fe\u5f62\u5f0f\u6253\u5f00","title":"\u4e71\u6570\u5047\u6587\uff08Lorem ipsum\uff09"},{"location":"ctf/ch1/#_1","text":"\u8f6c\u6362\u540e\uff0c\u6211\u4eec\u5f97\u5230\u8be5\u56fe\uff1a \u5728\u591a\u65b9\u9762\u5c1d\u8bd5\u540e\uff08\u4f8b\u5982\u56fe\u7247\u5bbd\u9ad8\u3001\u6587\u4ef6\u683c\u5f0f\u3001\u5185\u5bb9\u7f16\u7801\u7b49\uff09\uff0c\u4ecd\u6ca1\u6709\u660e\u663e\u53ef\u7591\u5730\u65b9\u540e\uff0c\u6211\u4eec\u5c1d\u8bd5\u5229\u7528\u8f83\u4e3a\u5168\u9762\u7684\u56fe\u7247\u5206\u6790\u5de5\u5177ImageMagick\u8fdb\u884c\u68c0\u6d4b\uff1a \u5229\u7528 identify -verbose level8.bmp \u547d\u4ee4\u6211\u4eec\u53d1\u73b0\u4e00\u4e2a\u53ef\u7591\u7684\u5730\u65b9 \u8868\u793a\u989c\u8272\u79cd\u7c7b\u6570\u591a\u8fbe42\u79cd\uff0c\u4f46\u4ece\u56fe\u4e2d\u5f88\u660e\u663e\u5e76\u6ca1\u6709\u8fd9\u4e48\u591a\uff0c\u901a\u8fc7\u8c03\u8282\u5bf9\u6bd4\u5ea6\u4e0e\u4eae\u5ea6\u540e \u53ef\u4ee5\u770b\u5230\u56fe\u7247\u4e0b\u65b9\u91c7\u53d6\u4e86\u7591\u4f3cLSB\u9690\u5199\u7684\u6280\u672f","title":"\u4f4d\u56fe\u6587\u4ef6"},{"location":"ctf/ch1/#_2","text":"\u5728\u56fe\u50cf\u6587\u4ef6\u4e2d\u9690\u85cf\u6570\u636e\u7684\u4e00\u79cd\u5e38\u89c1\u800c\u7b80\u5355\u7684\u9690\u5199\u6280\u672f \u901a\u8fc7\u7a0d\u5fae\u4fee\u6539\u56fe\u50cf\u50cf\u7d20\u7684RGB\u503c\uff0c\u6211\u4eec\u53ef\u4ee5\u5d4c\u5165\u8981\u9690\u85cf\u7684\u6570\u636e\uff1a\u5c06\u60f3\u8981\u9690\u85cf\u7684\u6570\u636e\u4f4d\u8986\u76d6\u7ea2\u8272\u3001\u7eff\u8272\u548c\u84dd\u8272\u901a\u9053\u7684\u6700\u4f4e\u6709\u6548\u4f4d\uff0c\u79f0\u4e3aLSB\u9690\u5199 \u4f8b\u5982\u5728\u8be5\u56fe\u4e2d\u6211\u4eec\u4ec5\u6539\u53d8\u4e86G\u901a\u9053\u4e0a\u7684LSB\uff0c\u5bf9\u989c\u8272\u7684\u6539\u53d8\u4e5f\u4ec5\u4ec5\u7531 #6490F1 \u53d8\u4e3a\u4e86 #6491F1\uff0c\u4ece\u8089\u773c\u4e0a\u662f\u96be\u4ee5\u533a\u5206\u7684\uff0c\u4f46\u7406\u8bba\u4e0a\u4e00\u5f20 W \\(\\times\\) H \u7684\u4f4d\u56fe\u80fd\u63d0\u4f9b\u6700\u5927 W \\(\\times\\) H \\(\\times\\) 3\\8 \u5b57\u8282\u7684\u9690\u5199\u7a7a\u95f4 \u5229\u7528\u5e38\u89c1\u7684LSB\u9690\u5199\u5de5\u5177\uff0c\u6211\u4eec\u53ef\u4ee5\u68c0\u6d4bbmp\u662f\u5426\u7ecf\u8fc7\u5e38\u89c1\u7684LSB\u52a0\u5bc6\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528zsteg\uff1a \u53ef\u4ee5\u770b\u5230\u5728b1\u4f4d\u4e0a\u7ecf\u8fc7LSB\u89e3\u5bc6\u68c0\u6d4b\u5230ELF\u7684\u6587\u4ef6\u6807\u8bc6\u7b26\uff0c\u8bf4\u660e\u8fd9\u6781\u6709\u53ef\u80fd\u662f\u88ab\u52a0\u5bc6\u9690\u85cf\u7684\u6587\u4ef6 \u6211\u4eec\u5229\u7528zsteg\u8fdb\u884c\u63d0\u53d6\uff1a \u901a\u8fc7file\u5de5\u5177\u53ef\u4ee5\u786e\u8ba4\u8fd9\u662f\u9700\u8981\u5f97\u5230\u7684\u9690\u5199ELF\u6587\u4ef6","title":"\u9690\u5199\u672f"},{"location":"ctf/ch2/","text":"FGSM\u7b80\u6613\u751f\u6210MNIST\u5bf9\u6297\u6837\u672c \u00b6 \u8bb0\u5f55\u4e00\u6b21\u56fe\u5bf9\u6297\u653b\u51fb\uff0c\u5c1d\u8bd5\u5feb\u901f\u68af\u5ea6\u7b26\u53f7\u653b\u51fb\uff08FGSM\uff09\u8ff7\u60d1MNIST\u5206\u7c7b\u5668 \u5bf9\u6297\u6027\u653b\u51fb\uff08Adversarial Attack\uff09 \u00b6 \u7531\u4e8e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u8f93\u5165\u5f62\u5f0f\u662f\u4e00\u79cd\u6570\u503c\u578b\u5411\u91cf\uff08numeric vectors\uff09\uff0c\u6240\u4ee5\u4fbf\u80fd\u8bbe\u8ba1\u4e00\u79cd\u6709\u9488\u5bf9\u6027\u7684\u6570\u503c\u578b\u5411\u91cf\u8ba9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u505a\u51fa\u8bef\u5224\uff0c\u8fd9\u4fbf\u88ab\u79f0\u4e3a\u5bf9\u6297\u6027\u653b\u51fb \u4ece\u6837\u672c\u7684\u89d2\u5ea6\u770b\uff0c\u88ab\u4fee\u6539\u8fc7\u540e\u7684\u5177\u6709\u9488\u5bf9\u6027\u7684\u6570\u503c\u578b\u5411\u91cf\u4fbf\u662f\u5bf9\u6297\u6837\u672c \u57fa\u4e8e\u653b\u51fb\u8005\u5148\u9a8c\u77e5\u8bc6\u4e0e\u653b\u51fb\u76ee\u6807\uff0c\u53ef\u4ee5\u5c06\u5bf9\u6297\u6027\u653b\u51fb\u5206\u4e3a\u4e0d\u540c\u7c7b\u578b\uff1a \u9ed1\u76d2\u653b\u51fb\uff08black-box\uff09\uff1a\u653b\u51fb\u8005\u53ea\u80fd\u8bbf\u95ee\u6a21\u578b\u7684\u8f93\u5165\u548c\u8f93\u51fa\uff0c\u5e76\u4e14\u5bf9\u5e95\u5c42\u67b6\u6784\u6216\u6743\u91cd\u4e00\u65e0\u6240\u77e5 \u767d\u76d2\u653b\u51fb\uff08white-box\uff09\uff1a\u653b\u51fb\u8005\u5177\u6709\u5bf9\u6a21\u578b\u7684\u5b8c\u6574\u77e5\u8bc6\u548c\u8bbf\u95ee\u6743\u9650\uff0c\u5305\u62ec\u4f53\u7cfb\u7ed3\u6784\u3001\u8f93\u5165\u3001\u8f93\u51fa\u548c\u6743\u91cd \u9519\u8bef\u5206\u7c7b\uff08misclassification\uff09\uff1a\u53ea\u5e0c\u671b\u8f93\u51fa\u5206\u7c7b\u9519\u8bef\uff0c\u800c\u4e0d\u5728\u4e4e\u65b0\u7684\u5206\u7c7b\u662f\u4ec0\u4e48 \u6e90/\u76ee\u6807\u9519\u8bef\u5206\u7c7b\uff08source/target misclassification\uff09\uff1a\u5e0c\u671b\u66f4\u6539\u6700\u521d\u5c5e\u4e8e\u7279\u5b9a\u6e90\u7c7b\u522b\u7684\u56fe\u50cf\uff0c\u4ece\u800c\u5c06\u5176\u5206\u7c7b\u4e3a\u7279\u5b9a\u76ee\u6807\u7c7b\u522b \u57fa\u4e8e\u5bf9\u6297\u653b\u51fb\u9886\u57df\uff0c\u4e2a\u4eba\u8ba4\u4e3a\u4e5f\u80fd\u5206\u6210\u591a\u7c7b\uff0c\u8f83\u4e3a\u666e\u904d\u7684\u662f\u56fe\u5bf9\u6297\u653b\u51fb FGSM\uff08Fast Gradient Sign Attack\uff09 \u00b6 *\u5feb\u901f\u68af\u5ea6\u7b26\u53f7\u653b\u51fb\uff08Fast Gradient Sign Attack\uff09*\u662f\u6700\u65e9\u4e14\u6700\u6d41\u884c\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u5f0f\u4e4b\u4e00 Goodfellow I J, Shlens J, Szegedy C. Explaining and harnessing adversarial examples[J]. arXiv preprint arXiv:1412.6572, 2014 FGSM\u7684\u601d\u60f3\u5341\u5206\u76f4\u89c2\u4e14\u6709\u6548\uff1a\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u65b9\u5f0f\uff0c\u5373\u68af\u5ea6\u6765\u8fdb\u884c\u653b\u51fb\uff0c\u5229\u7528\u6a21\u578b\u7684\u53cd\u5411\u4f20\u64ad\u68af\u5ea6\uff0c\u8c03\u6574\u6837\u672c\u6570\u636e\u4ee5\u6700\u5927\u5316\u635f\u5931 \u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c \\(x\\) \u662f\u88ab\u6b63\u786e\u5206\u7c7b\u4e3a\u201cpanda\u201d\u7684\u539f\u59cb\u8f93\u5165\u56fe\u50cf\uff0c \\(y\\) \u662f \\(x\\) \u7684\u771f\u5b9e\u6807\u7b7e\uff0c \\(\\mathbf \u03b8\\) \u4ee3\u8868\u6a21\u578b\u53c2\u6570\uff0c \\(J\uff08\\mathbf\u03b8 \uff0cx\uff0cy\uff09\\) \u662f\u7528\u4e8e\u8bad\u7ec3\u7f51\u7edc\u7684\u635f\u5931\u3002\u653b\u51fb\u5c06\u68af\u5ea6\u53cd\u6295\u5f71\u5230\u8f93\u5165\u6570\u636e\uff0c\u4ee5\u8ba1\u7b97 \\(\\nabla_{x}J\uff08\\mathbf \u03b8\uff0cx\uff0cy\uff09\\) \u3002\u7136\u540e\uff0c\u5b83\u5728\u65b9\u5411\uff08\u5373 \\(\\nabla_{x}J\uff08\\mathbf \u03b8\uff0cx \uff0cy\uff09\\) \u7b26\u53f7\uff09\u4e0a\u8c03\u6574\u8f93\u5165\u6570\u636e \\(x\\) \u4e00\u5b9a\u6b65\u5e45\uff08\u03b5\u6216\u56fe\u4e2d\u76840.007\uff09\u3002\u7ed3\u679c\u5f97\u5230\u7684\u6270\u52a8\u56fe\u50cf \\(x^{\\prime}\\) \u7136\u540e\u88ab\u76ee\u6807\u7f51\u7edc\u8bef\u5206\u7c7b\u4e3a\u201cgibbon\u201d \u4ee3\u7801\u5b9e\u73b0\uff08\u57fa\u4e8ePytorch & MNIST\uff09 \u00b6 \u8bad\u7ec3\u96c6\u4e0e\u6a21\u578b\u51c6\u5907 \u00b6 from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torchvision import datasets , transforms import numpy as np import matplotlib.pyplot as plt # NOTE: This is a hack to get around \"User-agent\" limitations when downloading MNIST datasets # see, https://github.com/pytorch/vision/issues/3497 for more information from six.moves import urllib opener = urllib . request . build_opener () opener . addheaders = [( 'User-agent' , 'Mozilla/5.0' )] urllib . request . install_opener ( opener ) epsilons = [ 0 , .05 , .1 , .15 , .2 , .25 , .3 ] pretrained_model = \"data/lenet_mnist_model.pth\" use_cuda = True # LeNet Model definition class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 10 , kernel_size = 5 ) self . conv2 = nn . Conv2d ( 10 , 20 , kernel_size = 5 ) self . conv2_drop = nn . Dropout2d () self . fc1 = nn . Linear ( 320 , 50 ) self . fc2 = nn . Linear ( 50 , 10 ) def forward ( self , x ): x = F . relu ( F . max_pool2d ( self . conv1 ( x ), 2 )) x = F . relu ( F . max_pool2d ( self . conv2_drop ( self . conv2 ( x )), 2 )) x = x . view ( - 1 , 320 ) x = F . relu ( self . fc1 ( x )) x = F . dropout ( x , training = self . training ) x = self . fc2 ( x ) return F . log_softmax ( x , dim = 1 ) # MNIST Test dataset and dataloader declaration test_loader = torch . utils . data . DataLoader ( datasets . MNIST ( '../data' , train = False , download = True , transform = transforms . Compose ([ transforms . ToTensor (), ])), batch_size = 1 , shuffle = True ) # Define what device we are using print ( \"CUDA Available: \" , torch . cuda . is_available ()) device = torch . device ( \"cuda\" if ( use_cuda and torch . cuda . is_available ()) else \"cpu\" ) # Initialize the network model = Net () . to ( device ) # Load the pretrained model model . load_state_dict ( torch . load ( pretrained_model , map_location = 'cpu' )) # Set the model in evaluation mode. In this case this is for the Dropout layers model . eval () FGSM\u5b9e\u73b0 \u00b6 # FGSM attack code def fgsm_attack ( image , epsilon , data_grad ): # Collect the element-wise sign of the data gradient sign_data_grad = data_grad . sign () # Create the perturbed image by adjusting each pixel of the input image perturbed_image = image + epsilon * sign_data_grad # Adding clipping to maintain [0,1] range perturbed_image = torch . clamp ( perturbed_image , 0 , 1 ) # Return the perturbed image return perturbed_image \u6d4b\u8bd5\u51fd\u6570 \u00b6 def test ( model , device , test_loader , epsilon ): # Accuracy counter correct = 0 adv_examples = [] # Loop over all examples in test set for data , target in test_loader : # Send the data and label to the device data , target = data . to ( device ), target . to ( device ) # Set requires_grad attribute of tensor. Important for Attack data . requires_grad = True # Forward pass the data through the model output = model ( data ) init_pred = output . max ( 1 , keepdim = True )[ 1 ] # get the index of the max log-probability # If the initial prediction is wrong, dont bother attacking, just move on if init_pred . item () != target . item (): continue # Calculate the loss loss = F . nll_loss ( output , target ) # Zero all existing gradients model . zero_grad () # Calculate gradients of model in backward pass loss . backward () # Collect datagrad data_grad = data . grad . data # Call FGSM Attack perturbed_data = fgsm_attack ( data , epsilon , data_grad ) # Re-classify the perturbed image output = model ( perturbed_data ) # Check for success final_pred = output . max ( 1 , keepdim = True )[ 1 ] # get the index of the max log-probability if final_pred . item () == target . item (): correct += 1 # Special case for saving 0 epsilon examples if ( epsilon == 0 ) and ( len ( adv_examples ) < 5 ): adv_ex = perturbed_data . squeeze () . detach () . cpu () . numpy () adv_examples . append ( ( init_pred . item (), final_pred . item (), adv_ex ) ) else : # Save some adv examples for visualization later if len ( adv_examples ) < 5 : adv_ex = perturbed_data . squeeze () . detach () . cpu () . numpy () adv_examples . append ( ( init_pred . item (), final_pred . item (), adv_ex ) ) # Calculate final accuracy for this epsilon final_acc = correct / float ( len ( test_loader )) print ( \"Epsilon: {} \\t Test Accuracy = {} / {} = {} \" . format ( epsilon , correct , len ( test_loader ), final_acc )) # Return the accuracy and an adversarial example return final_acc , adv_examples \u6d4b\u8bd5 \u00b6 accuracies = [] examples = [] # Run test for each epsilon for eps in epsilons : acc , ex = test ( model , device , test_loader , eps ) accuracies . append ( acc ) examples . append ( ex ) \u53ef\u89c6\u5316 \u00b6 plt . figure ( figsize = ( 5 , 5 )) plt . plot ( epsilons , accuracies , \"*-\" ) plt . yticks ( np . arange ( 0 , 1.1 , step = 0.1 )) plt . xticks ( np . arange ( 0 , .35 , step = 0.05 )) plt . title ( \"Accuracy vs Epsilon\" ) plt . xlabel ( \"Epsilon\" ) plt . ylabel ( \"Accuracy\" ) plt . show () \u5bf9\u6297\u6837\u672c\u90e8\u5206\u5c55\u793a \u00b6 # Plot several examples of adversarial samples at each epsilon cnt = 0 plt . figure ( figsize = ( 8 , 10 )) for i in range ( len ( epsilons )): for j in range ( len ( examples [ i ])): cnt += 1 plt . subplot ( len ( epsilons ), len ( examples [ 0 ]), cnt ) plt . xticks ([], []) plt . yticks ([], []) if j == 0 : plt . ylabel ( \"Eps: {} \" . format ( epsilons [ i ]), fontsize = 14 ) orig , adv , ex = examples [ i ][ j ] plt . title ( \" {} -> {} \" . format ( orig , adv )) plt . imshow ( ex , cmap = \"gray\" ) plt . tight_layout () plt . show ()","title":"FGSM\u653b\u51fb"},{"location":"ctf/ch2/#fgsmmnist","text":"\u8bb0\u5f55\u4e00\u6b21\u56fe\u5bf9\u6297\u653b\u51fb\uff0c\u5c1d\u8bd5\u5feb\u901f\u68af\u5ea6\u7b26\u53f7\u653b\u51fb\uff08FGSM\uff09\u8ff7\u60d1MNIST\u5206\u7c7b\u5668","title":"FGSM\u7b80\u6613\u751f\u6210MNIST\u5bf9\u6297\u6837\u672c"},{"location":"ctf/ch2/#adversarial-attack","text":"\u7531\u4e8e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u8f93\u5165\u5f62\u5f0f\u662f\u4e00\u79cd\u6570\u503c\u578b\u5411\u91cf\uff08numeric vectors\uff09\uff0c\u6240\u4ee5\u4fbf\u80fd\u8bbe\u8ba1\u4e00\u79cd\u6709\u9488\u5bf9\u6027\u7684\u6570\u503c\u578b\u5411\u91cf\u8ba9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u505a\u51fa\u8bef\u5224\uff0c\u8fd9\u4fbf\u88ab\u79f0\u4e3a\u5bf9\u6297\u6027\u653b\u51fb \u4ece\u6837\u672c\u7684\u89d2\u5ea6\u770b\uff0c\u88ab\u4fee\u6539\u8fc7\u540e\u7684\u5177\u6709\u9488\u5bf9\u6027\u7684\u6570\u503c\u578b\u5411\u91cf\u4fbf\u662f\u5bf9\u6297\u6837\u672c \u57fa\u4e8e\u653b\u51fb\u8005\u5148\u9a8c\u77e5\u8bc6\u4e0e\u653b\u51fb\u76ee\u6807\uff0c\u53ef\u4ee5\u5c06\u5bf9\u6297\u6027\u653b\u51fb\u5206\u4e3a\u4e0d\u540c\u7c7b\u578b\uff1a \u9ed1\u76d2\u653b\u51fb\uff08black-box\uff09\uff1a\u653b\u51fb\u8005\u53ea\u80fd\u8bbf\u95ee\u6a21\u578b\u7684\u8f93\u5165\u548c\u8f93\u51fa\uff0c\u5e76\u4e14\u5bf9\u5e95\u5c42\u67b6\u6784\u6216\u6743\u91cd\u4e00\u65e0\u6240\u77e5 \u767d\u76d2\u653b\u51fb\uff08white-box\uff09\uff1a\u653b\u51fb\u8005\u5177\u6709\u5bf9\u6a21\u578b\u7684\u5b8c\u6574\u77e5\u8bc6\u548c\u8bbf\u95ee\u6743\u9650\uff0c\u5305\u62ec\u4f53\u7cfb\u7ed3\u6784\u3001\u8f93\u5165\u3001\u8f93\u51fa\u548c\u6743\u91cd \u9519\u8bef\u5206\u7c7b\uff08misclassification\uff09\uff1a\u53ea\u5e0c\u671b\u8f93\u51fa\u5206\u7c7b\u9519\u8bef\uff0c\u800c\u4e0d\u5728\u4e4e\u65b0\u7684\u5206\u7c7b\u662f\u4ec0\u4e48 \u6e90/\u76ee\u6807\u9519\u8bef\u5206\u7c7b\uff08source/target misclassification\uff09\uff1a\u5e0c\u671b\u66f4\u6539\u6700\u521d\u5c5e\u4e8e\u7279\u5b9a\u6e90\u7c7b\u522b\u7684\u56fe\u50cf\uff0c\u4ece\u800c\u5c06\u5176\u5206\u7c7b\u4e3a\u7279\u5b9a\u76ee\u6807\u7c7b\u522b \u57fa\u4e8e\u5bf9\u6297\u653b\u51fb\u9886\u57df\uff0c\u4e2a\u4eba\u8ba4\u4e3a\u4e5f\u80fd\u5206\u6210\u591a\u7c7b\uff0c\u8f83\u4e3a\u666e\u904d\u7684\u662f\u56fe\u5bf9\u6297\u653b\u51fb","title":"\u5bf9\u6297\u6027\u653b\u51fb\uff08Adversarial Attack\uff09"},{"location":"ctf/ch2/#fgsmfast-gradient-sign-attack","text":"*\u5feb\u901f\u68af\u5ea6\u7b26\u53f7\u653b\u51fb\uff08Fast Gradient Sign Attack\uff09*\u662f\u6700\u65e9\u4e14\u6700\u6d41\u884c\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u5f0f\u4e4b\u4e00 Goodfellow I J, Shlens J, Szegedy C. Explaining and harnessing adversarial examples[J]. arXiv preprint arXiv:1412.6572, 2014 FGSM\u7684\u601d\u60f3\u5341\u5206\u76f4\u89c2\u4e14\u6709\u6548\uff1a\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u65b9\u5f0f\uff0c\u5373\u68af\u5ea6\u6765\u8fdb\u884c\u653b\u51fb\uff0c\u5229\u7528\u6a21\u578b\u7684\u53cd\u5411\u4f20\u64ad\u68af\u5ea6\uff0c\u8c03\u6574\u6837\u672c\u6570\u636e\u4ee5\u6700\u5927\u5316\u635f\u5931 \u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c \\(x\\) \u662f\u88ab\u6b63\u786e\u5206\u7c7b\u4e3a\u201cpanda\u201d\u7684\u539f\u59cb\u8f93\u5165\u56fe\u50cf\uff0c \\(y\\) \u662f \\(x\\) \u7684\u771f\u5b9e\u6807\u7b7e\uff0c \\(\\mathbf \u03b8\\) \u4ee3\u8868\u6a21\u578b\u53c2\u6570\uff0c \\(J\uff08\\mathbf\u03b8 \uff0cx\uff0cy\uff09\\) \u662f\u7528\u4e8e\u8bad\u7ec3\u7f51\u7edc\u7684\u635f\u5931\u3002\u653b\u51fb\u5c06\u68af\u5ea6\u53cd\u6295\u5f71\u5230\u8f93\u5165\u6570\u636e\uff0c\u4ee5\u8ba1\u7b97 \\(\\nabla_{x}J\uff08\\mathbf \u03b8\uff0cx\uff0cy\uff09\\) \u3002\u7136\u540e\uff0c\u5b83\u5728\u65b9\u5411\uff08\u5373 \\(\\nabla_{x}J\uff08\\mathbf \u03b8\uff0cx \uff0cy\uff09\\) \u7b26\u53f7\uff09\u4e0a\u8c03\u6574\u8f93\u5165\u6570\u636e \\(x\\) \u4e00\u5b9a\u6b65\u5e45\uff08\u03b5\u6216\u56fe\u4e2d\u76840.007\uff09\u3002\u7ed3\u679c\u5f97\u5230\u7684\u6270\u52a8\u56fe\u50cf \\(x^{\\prime}\\) \u7136\u540e\u88ab\u76ee\u6807\u7f51\u7edc\u8bef\u5206\u7c7b\u4e3a\u201cgibbon\u201d","title":"FGSM\uff08Fast Gradient Sign Attack\uff09"},{"location":"ctf/ch2/#pytorch-mnist","text":"","title":"\u4ee3\u7801\u5b9e\u73b0\uff08\u57fa\u4e8ePytorch &amp; MNIST\uff09"},{"location":"ctf/ch2/#_1","text":"from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torchvision import datasets , transforms import numpy as np import matplotlib.pyplot as plt # NOTE: This is a hack to get around \"User-agent\" limitations when downloading MNIST datasets # see, https://github.com/pytorch/vision/issues/3497 for more information from six.moves import urllib opener = urllib . request . build_opener () opener . addheaders = [( 'User-agent' , 'Mozilla/5.0' )] urllib . request . install_opener ( opener ) epsilons = [ 0 , .05 , .1 , .15 , .2 , .25 , .3 ] pretrained_model = \"data/lenet_mnist_model.pth\" use_cuda = True # LeNet Model definition class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 10 , kernel_size = 5 ) self . conv2 = nn . Conv2d ( 10 , 20 , kernel_size = 5 ) self . conv2_drop = nn . Dropout2d () self . fc1 = nn . Linear ( 320 , 50 ) self . fc2 = nn . Linear ( 50 , 10 ) def forward ( self , x ): x = F . relu ( F . max_pool2d ( self . conv1 ( x ), 2 )) x = F . relu ( F . max_pool2d ( self . conv2_drop ( self . conv2 ( x )), 2 )) x = x . view ( - 1 , 320 ) x = F . relu ( self . fc1 ( x )) x = F . dropout ( x , training = self . training ) x = self . fc2 ( x ) return F . log_softmax ( x , dim = 1 ) # MNIST Test dataset and dataloader declaration test_loader = torch . utils . data . DataLoader ( datasets . MNIST ( '../data' , train = False , download = True , transform = transforms . Compose ([ transforms . ToTensor (), ])), batch_size = 1 , shuffle = True ) # Define what device we are using print ( \"CUDA Available: \" , torch . cuda . is_available ()) device = torch . device ( \"cuda\" if ( use_cuda and torch . cuda . is_available ()) else \"cpu\" ) # Initialize the network model = Net () . to ( device ) # Load the pretrained model model . load_state_dict ( torch . load ( pretrained_model , map_location = 'cpu' )) # Set the model in evaluation mode. In this case this is for the Dropout layers model . eval ()","title":"\u8bad\u7ec3\u96c6\u4e0e\u6a21\u578b\u51c6\u5907"},{"location":"ctf/ch2/#fgsm","text":"# FGSM attack code def fgsm_attack ( image , epsilon , data_grad ): # Collect the element-wise sign of the data gradient sign_data_grad = data_grad . sign () # Create the perturbed image by adjusting each pixel of the input image perturbed_image = image + epsilon * sign_data_grad # Adding clipping to maintain [0,1] range perturbed_image = torch . clamp ( perturbed_image , 0 , 1 ) # Return the perturbed image return perturbed_image","title":"FGSM\u5b9e\u73b0"},{"location":"ctf/ch2/#_2","text":"def test ( model , device , test_loader , epsilon ): # Accuracy counter correct = 0 adv_examples = [] # Loop over all examples in test set for data , target in test_loader : # Send the data and label to the device data , target = data . to ( device ), target . to ( device ) # Set requires_grad attribute of tensor. Important for Attack data . requires_grad = True # Forward pass the data through the model output = model ( data ) init_pred = output . max ( 1 , keepdim = True )[ 1 ] # get the index of the max log-probability # If the initial prediction is wrong, dont bother attacking, just move on if init_pred . item () != target . item (): continue # Calculate the loss loss = F . nll_loss ( output , target ) # Zero all existing gradients model . zero_grad () # Calculate gradients of model in backward pass loss . backward () # Collect datagrad data_grad = data . grad . data # Call FGSM Attack perturbed_data = fgsm_attack ( data , epsilon , data_grad ) # Re-classify the perturbed image output = model ( perturbed_data ) # Check for success final_pred = output . max ( 1 , keepdim = True )[ 1 ] # get the index of the max log-probability if final_pred . item () == target . item (): correct += 1 # Special case for saving 0 epsilon examples if ( epsilon == 0 ) and ( len ( adv_examples ) < 5 ): adv_ex = perturbed_data . squeeze () . detach () . cpu () . numpy () adv_examples . append ( ( init_pred . item (), final_pred . item (), adv_ex ) ) else : # Save some adv examples for visualization later if len ( adv_examples ) < 5 : adv_ex = perturbed_data . squeeze () . detach () . cpu () . numpy () adv_examples . append ( ( init_pred . item (), final_pred . item (), adv_ex ) ) # Calculate final accuracy for this epsilon final_acc = correct / float ( len ( test_loader )) print ( \"Epsilon: {} \\t Test Accuracy = {} / {} = {} \" . format ( epsilon , correct , len ( test_loader ), final_acc )) # Return the accuracy and an adversarial example return final_acc , adv_examples","title":"\u6d4b\u8bd5\u51fd\u6570"},{"location":"ctf/ch2/#_3","text":"accuracies = [] examples = [] # Run test for each epsilon for eps in epsilons : acc , ex = test ( model , device , test_loader , eps ) accuracies . append ( acc ) examples . append ( ex )","title":"\u6d4b\u8bd5"},{"location":"ctf/ch2/#_4","text":"plt . figure ( figsize = ( 5 , 5 )) plt . plot ( epsilons , accuracies , \"*-\" ) plt . yticks ( np . arange ( 0 , 1.1 , step = 0.1 )) plt . xticks ( np . arange ( 0 , .35 , step = 0.05 )) plt . title ( \"Accuracy vs Epsilon\" ) plt . xlabel ( \"Epsilon\" ) plt . ylabel ( \"Accuracy\" ) plt . show ()","title":"\u53ef\u89c6\u5316"},{"location":"ctf/ch2/#_5","text":"# Plot several examples of adversarial samples at each epsilon cnt = 0 plt . figure ( figsize = ( 8 , 10 )) for i in range ( len ( epsilons )): for j in range ( len ( examples [ i ])): cnt += 1 plt . subplot ( len ( epsilons ), len ( examples [ 0 ]), cnt ) plt . xticks ([], []) plt . yticks ([], []) if j == 0 : plt . ylabel ( \"Eps: {} \" . format ( epsilons [ i ]), fontsize = 14 ) orig , adv , ex = examples [ i ][ j ] plt . title ( \" {} -> {} \" . format ( orig , adv )) plt . imshow ( ex , cmap = \"gray\" ) plt . tight_layout () plt . show ()","title":"\u5bf9\u6297\u6837\u672c\u90e8\u5206\u5c55\u793a"},{"location":"web/todo/","text":"Todo \u00b6","title":"\u817e\u8baf\u4e91"},{"location":"web/todo/#todo","text":"","title":"Todo"},{"location":"web/todo1/","text":"Todo \u00b6","title":"Nginx"},{"location":"web/todo1/#todo","text":"","title":"Todo"},{"location":"web/todo2/","text":"Todo \u00b6","title":"uWSGI"},{"location":"web/todo2/#todo","text":"","title":"Todo"},{"location":"web/todo3/","text":"Todo \u00b6","title":"Flask"},{"location":"web/todo3/#todo","text":"","title":"Todo"},{"location":"web/todo4/","text":"Todo \u00b6","title":"Vue2&3"},{"location":"web/todo4/#todo","text":"","title":"Todo"}]}